# Documentation and Mathematical foundations (concise)

## Thematic overview: sequence of events and where uncertainty enters

This describes, in practical terms, how a CIB workflow becomes probabilistic, where uncertainty and stochasticity enter the process, and how they manifest in plots (including median trajectories). The aim is to make explicit the sequence of computations that sit behind the deterministic CIB principles described below.

## Scope note: two different “probabilistic” features

This repository contains **two** distinct uses of “probabilistic”, which are easy to conflate:

- **Simulation-first probabilistic CIB (this document)**: uncertainty is introduced into the CIB simulation model (e.g. confidence-coded sampling of the CIM, structural shocks, AR(1) dynamic shocks, thresholds, cyclic descriptors). Outputs are empirical frequencies from Monte Carlo ensembles and/or branching pathway graphs.
- **Joint-distribution probabilistic CIA (experimental, `cib.prob`)**: “probability” means an explicit fitted joint distribution \(P(x)\) over discrete factors, constrained by user-specified marginals and cross-impact multipliers (probability ratios). This is not derived from CIB impact scores, and it does not use the shocks/threshold/cycle simulation machinery described below.

For the experimental `cib.prob` quickstart and current limitations (dense small-space fitting; dynamic mode is currently per-period `refit` only), see `docs/Probabilistic_CIA.md` and the examples `examples/example_probabilistic_cia_static.py` and `examples/example_probabilistic_cia_dynamic_refit.py`.

### 1) Deterministic core (workshop “central estimate”)

At the core of CIB is a deterministic cross-impact matrix (CIM) \(C\) populated by "workshop judgements". Given a scenario \(z\) (one state chosen per descriptor), impact scores \(\theta_{j,l}(z)\) are computed and the consistency principle (maximum score condition) is applied to determine whether \(z\) is consistent. Succession operators iterate a scenario towards an attractor (typically a fixed point, sometimes a cycle), which provides a canonical “consistent scenario” implied by the workshop’s central judgements.

### 2) Judgement uncertainty (confidence-coded sampling)

Workshop participants are typically more confident about some judgements than others. In this implementation, a confidence code \(c\in\{1,\dots,5\}\) is converted into a standard deviation \(\sigma(c)\). A sampled matrix \(C^{(m)}\) is generated by drawing each cell around its mean judgement and clipping to \([-3,+3]\). This is the first place where runs diverge: different samples imply different impact balances and may yield different attractors.

Optionally, uncertainty can be made time-dependent (a common elicitation assumption): \(\sigma\) may be scaled up for longer horizons, reflecting that respondents are less certain about the longer-term future.

### 3) Structural shocks (stress-testing, regime perturbations)

Structural shocks represent persistent or structural perturbations to the CIM, distinct from judgement uncertainty. Conceptually, they answer: “If the world deviates from the elicited system in a persistent way, how robust are our consistent scenarios?” Structural shocks perturb the CIM and then the consistency/succession computations are repeated under the perturbed matrix.

### 4) Dynamic shocks (AR(1) stochastic forcing during succession)

Dynamic shocks are applied at the impact-balance level during within-period succession. They are designed to model time-varying disturbances that can (a) nudge balances between close competing states and (b) occasionally induce switching or activate threshold-triggered regime shifts. Persistence is introduced by the AR(1) structure: shocks are not independent across periods, so sequences can exhibit momentum.

Fat-tailed innovations (Student-\(t\)) and jump components provide “rare event” behaviour: a small number of runs can experience large disturbances, producing visibly different trajectories.

### 4b) Realised versus equilibrium trajectories (recommended for research reporting)

Two complementary outputs are useful when dynamic shocks are present:

- **Realised trajectory**: the per-period scenario produced by shock-aware succession. This is the natural object for studying perturbation-driven switching and threshold activation. A realised scenario is not required to be CIB-consistent with respect to an unshocked matrix because selection is performed under perturbed scores \(\theta'=\theta+\eta\).
- **Equilibrium trajectory (optional)**: a per-period unshocked relaxation that starts from the realised scenario and applies standard succession on the same active period matrix. This produces a scenario that is CIB-consistent with respect to the period matrix used for that period.

This separation is recommended because it preserves the classical CIB definition of consistency for equilibrium reporting while retaining stochastic forcing as a mechanism for transitions. The gap between realised and equilibrium scenarios (for example, Hamming distance or consistency-margin differences) can be used as a diagnostic of proximity to switching thresholds or of “shock pressure”.

### 5) Threshold rules and cyclic (exogenous/inertial) descriptors

Two additional mechanisms govern when and how the active CIM changes and how certain descriptors evolve:

- **Threshold rules** conditionally modify the active CIM based on the current scenario (e.g. tipping points or policy regimes). A small disturbance can move the system across a threshold, which then changes the CIM and alters subsequent attractors.
- **Cyclic descriptors** evolve via an explicit transition matrix between periods (often with strong persistence), representing exogenous drift or inertia that is not endogenously resolved by CIB within a period. These descriptors are “locked” during within-period succession so that their exogenous evolution is not overwritten.

Threshold rule timing:

- In `DynamicCIB.simulate_path()`, cyclic transitions (if configured) are applied at the start of each new period (t > 0), and threshold rules are then evaluated on the resulting (post-cyclic) scenario state to select the active period matrix used for within-period succession.
- In `BranchingPathwayBuilder.build()`, threshold rules are evaluated on the parent scenario (period t) to construct the active CIM used for the transition into period t+1.

These conventions are both valid; the key is to be explicit about which scenario state a threshold condition is evaluated against, especially when threshold conditions depend on cyclic descriptors.

### 6) What a “Monte Carlo run” is (and why it is a single path)

A single Monte Carlo run produces one realised pathway \(z_{t_0}, z_{t_1}, \dots\) because one draw of the stochastic elements (judgement sampling, shocks, cyclic transitions) is made and then the pathway is advanced forward in time. The branching behaviour is not within a single run; it emerges across many runs. The distributional plots (probability bands, fan charts) are summaries of the ensemble.

### 7) Branching pathway graphs versus Monte Carlo ensembles

The ensemble can be represented in two complementary ways:

- **Monte Carlo ensemble (simulation-first)**: many complete pathways are simulated and summarised. This is the most direct estimator for per-period marginals such as \(P(z_j(t)=s)\), quantiles, and expectations.
- **Branching pathway graph (enumerate-or-sample)**: an explicit per-period graph is built whose nodes are scenarios (typically attractors) and whose edges carry transition weights. In sampling mode, those weights are estimated from repeated stochastic transitions out of each node. The resulting graph can be propagated forward to obtain the same per-period marginals as the Monte Carlo ensemble, subject to sampling noise and any pruning/caps applied for readability.

### 8) Network analysis layer (impact networks and scenario similarity networks)

In addition to the deterministic/probabilistic CIB computations above, a network-analysis layer is provided by this implementation for two distinct graph objects:

1. **Impact network (descriptor graph)**: a directed graph over descriptors that captures aggregated or state-specific influences.
   - Nodes are descriptors.
   - A directed edge \(i \rightarrow j\) exists when the corresponding CIB impacts are non-zero under the chosen aggregation rule.
   - For each ordered pair \((i,j)\), impacts are aggregated across all state pairs \((k,l)\) using a specified rule (for example, mean absolute or mean signed), producing:
     - A signed representative weight \(w_{i \rightarrow j}\) (promoting vs. hindering).
     - An absolute weight \(|w_{i \rightarrow j}|\) used for magnitude-based analysis and visualization.
   - Centrality measures and pathway enumeration are then applied to this descriptor graph.

2. **Scenario similarity network (scenario graph)**: a graph over scenarios that is used as a visual summary of an ensemble at a fixed period.
   - Nodes are scenarios (state assignment vectors) at a single period \(t\), typically the final period in a dynamic run.
   - Node weights are the empirical frequencies from the Monte Carlo ensemble, \(n(z,t)\), where \(n\) counts how many runs produced scenario \(z\) at time \(t\).
   - Edges represent similarity, not temporal transition. A common rule is Hamming distance:
     \[
     d(z,z') = \sum_{j=1}^{N}\mathbf{1}\{z_j \ne z'_j\}.
     \]
     Scenarios are connected when \(d(z,z')\) is small, and an edge weight can be defined as \(1/(1+d)\).

This separation matters: the impact network is a structural summary of the CIM, while the scenario similarity network is an empirical summary of the simulated distribution over scenarios at a specific time.

Implementation notes:

- The network analysis layer is implemented in `cib/network_analysis.py`.
- Community detection uses Louvain clustering via `networkx.community.louvain_communities()`, which requires NetworkX 3.0 or newer.
- The example notebook generates a final-period scenario similarity plot and writes a text file with the plotted scenario definitions and their Monte Carlo counts.

### 9) How median trajectories arise (and why they can look “flat”)

Numeric summaries for an ordered descriptor are included in the plots by applying a mapping \(\mathrm{map}(s)\) from each discrete state \(s\) to a numeric value. Given per-period state probabilities \(P_t(s)\), the expected value is:

\[
\mathbb{E}[X_t] = \sum_s P_t(s)\,\mathrm{map}(s)
\]

Quantiles (including the median) are defined with respect to the induced discrete distribution over \(\mathrm{map}(s)\). A median can appear constant over time when the same state (often the middle state) retains at least 50% probability across periods; in that case the 0.5-quantile does not move even though uncertainty bands widen and the expected value can drift.

### 10) Cycle detection in succession and dynamic simulations

Cycles occur when succession operators revisit previously encountered scenarios, creating a periodic attractor rather than a fixed point. This section explains when cycles occur, how they are detected, and how they are handled in different contexts.

#### When cycles occur

Cycles can emerge in CIB succession when:
- Multiple scenarios have equal or near-equal impact scores, causing succession to alternate between them
- Stochastic succession introduces randomness that prevents convergence to a single fixed point
- System dynamics create periodic patterns (e.g., seasonal effects, alternating policy regimes)

#### Cycle detection mechanism

The `SuccessionOperator.find_attractor()` method detects cycles by maintaining a visited set of scenarios. When a successor scenario has been encountered before, a cycle is identified:

1. Succession proceeds from an initial scenario
2. Each successor is checked against previously visited scenarios
3. If a duplicate is found, the cycle is extracted (from first occurrence to current)
4. `AttractorResult.is_cycle` is set to `True` and `attractor` contains the cycle list

Implementation note:

- The cycle list contains the distinct periodic states only. The repeated closing state
  (the first state repeated at the end when a loop is detected) is not included. This
  avoids double-counting and prevents bias when a cycle state is selected at random.

#### Handling cycles in deterministic succession

For deterministic succession (no stochastic elements):
- Cycles are detected deterministically
- The cycle list contains all scenarios in the periodic sequence
- The first scenario in the cycle is typically used as the representative attractor

#### Handling cycles in stochastic succession

When dynamic shocks or judgment uncertainty are present:
- Cycles may be detected differently across runs due to stochasticity
- The `tie_break` parameter in `DynamicCIB.simulate_path()` controls cycle handling:
  - `"deterministic_first"`: Always selects the first scenario in the cycle
  - `"random"`: Randomly selects a scenario from the cycle using the random number generator
- This ensures reproducibility while allowing stochastic variation

#### Cycle detection in branching pathways

In `BranchingPathwayBuilder`, cycles are handled by selecting the first scenario in the cycle as the representative node. This prevents infinite loops while preserving the cycle information in the succession path.

#### Practical implications

- **Fixed points vs cycles**: Fixed points represent stable system states; cycles represent periodic dynamics
- **Interpretation**: Cycles may indicate system instability or alternating regimes
- **Stability**: Systems with cycles may be more sensitive to perturbations than fixed-point attractors

## Impact scores and balances

For a scenario \(z = [z_1,\dots,z_N]\), the impact score of target descriptor \(j\) being in state \(l\) is:

\[
\theta_{j,l}(z) = \sum_{i \ne j} C_{i\to j}(z_i, l)
\]

where \(C_{i\to j}(k,l)\) is the impact of source descriptor \(i\) being in state \(k\) on target descriptor \(j\) being in state \(l\).

The impact balance for descriptor \(j\) is the vector \((\theta_{j,1},\dots,\theta_{j,s_j})\).

## Consistency principle

A scenario is consistent if, for every descriptor \(j\), the chosen state \(z_j\) achieves the maximum (ties allowed):

\[
\theta_{j,z_j}(z) \ge \theta_{j,l}(z)\quad \forall l
\]

## Practical uncertainty model (confidence-coded)

We model each judgment cell as a bounded “noise around the workshop mean”:

\[
C_{i\to j}(k,l) \sim \mathrm{Normal}(\mu_{i,j,k,l}, \sigma^2_{i,j,k,l})\ \text{clipped to }[-3,+3]
\]

with \(\mu\) from the point judgment table and \(\sigma\) from a confidence code \(c\in\{1,\dots,5\}\).

Default mapping (must match `cib.example_data.CONFIDENCE_TO_SIGMA`):

- \(c=5\): \(\sigma=0.2\)
- \(c=4\): \(\sigma=0.5\)
- \(c=3\): \(\sigma=0.8\)
- \(c=2\): \(\sigma=1.2\)
- \(c=1\): \(\sigma=1.5\)

## Probabilistic consistency

For a fixed candidate scenario \(z\), estimate:

\[
P(\mathrm{consistent}\mid z) \approx \frac{1}{M}\sum_{m=1}^M \mathbf{1}\{z\ \text{is consistent in sampled }C^{(m)}\}
\]

## Structural shocks

The CIM is perturbed by structural shock stress testing:

\[
C \leftarrow C + \varepsilon,\qquad \varepsilon \sim \mathcal{N}(0, \Sigma)
\]

The default is independent shocks (diagonal \(\Sigma\)); correlated shocks are supported via an explicit correlation matrix.

### Optional fat tails / rare events

For “rare event” realism, disturbances can be sampled from heavy-tailed or jump-mixture distributions:

- **Student-t shocks** (fat tails): \(\varepsilon \sim t_{\nu}\) scaled to match a target variance.
- **Normal + jumps**: \(\varepsilon = \xi + J\), where \(\xi\sim\mathcal{N}(0,\sigma^2)\) and \(J\) is an independent jump term that is applied with probability \(p\).

In the current implementation, correlated structural shocks remain Gaussian by construction; non-Gaussian structural shocks are supported for independent (per-cell) shocks.

## Dynamic shocks (AR(1))

Dynamic shocks are applied at the impact-balance level during within-period succession:

\[
\theta'_{j,l}(t) = \theta_{j,l}(t) + \eta_{j,l}(t)
\]

\[
\eta_{j,l}(t) = \rho\,\eta_{j,l}(t-1) + u_{j,l}(t)
\]

The innovation \(u_{j,l}(t)\) is mean-zero with long-run scale \(\tau\). Common choices are:

- Gaussian innovations: \(u_{j,l}(t)\sim \mathcal{N}(0,(1-\rho^2)\tau^2)\)
- Student-t innovations (fat tails): \(u_{j,l}(t)\sim t_{\nu}\) scaled to match \((1-\rho^2)\tau^2\)
- Jump innovations: with probability \(p\), a jump term is added to the innovation (rare events)

## Branching pathways (hybrid enumeration + sampling)

When transformation pathways are constructed across sub-periods, two complementary modes are useful:

- **Enumeration (enumeration-based branching)**: if the scenario space is small, all consistent scenarios for the active CIM in a sub-period are enumerated and treated as the scenario set for that period.
  - Uses a deterministic base matrix for transitions (no judgement-uncertainty sampling, no structural shocks).
  - Transition probabilities are exact (uniform over enumerated consistent scenarios, per parent).

- **Sampling (Monte Carlo)**: if the scenario space is large, the reachable scenario set and transition probabilities are approximated by repeated random restarts, uncertainty/shock sampling, and succession.
  - Respects judgement uncertainty (`judgment_sigma_scale_by_period`) and structural shocks (`structural_sigma`) when configured.
  - Transition probabilities are estimated from counts and converge with more samples.

Important:

- Enumeration is used when scenario space size is <= `max_states_to_enumerate`; sampling is used otherwise.
- If you set `structural_sigma` and/or `judgment_sigma_scale_by_period` but enumeration mode is selected, those parameters are ignored by design. To ensure uncertainty is applied, decrease `max_states_to_enumerate` to force sampling mode.

The hybrid “enumerate-or-sample” approach uses enumeration when feasible and otherwise sampling, yielding a branching pathway graph with weighted edges between consecutive periods.

## Transformation matrices

Transformation matrices identify which perturbations cause transitions between scenarios. For each scenario pair (i, j), different perturbation types (structural shocks, dynamic shocks, judgment uncertainty) are tested to determine which perturbations cause transitions from scenario i to scenario j. A transformation is considered successful if the attractor reached from scenario i equals scenario j or is within Hamming distance 1.

Notes:

- For dynamic shocks, a single AR(1) shock field \(\eta\) is sampled at the (descriptor, candidate_state) level using the same generator as the dynamic simulation layer. A single pseudo-period is used because the transformation-matrix test is a static (one-step) perturbation experiment rather than a multi-period time series.
- If succession yields a cycle, the transformation condition is evaluated against all states in the cycle (not only a representative element).

The `TransformationMatrixBuilder` class builds transformation matrices by testing perturbations across scenario pairs.

## Expert aggregation (weighted)

For a cell with expert means \(\mu_i\), standard deviations \(\sigma_i\), and weights \(w_i\) (renormalized over experts that provided the cell):

\[
\mu = \sum_i w_i \mu_i
\]

\[
\sigma^2 = \sum_i w_i^2\sigma_i^2 + \sum_i w_i(\mu_i-\mu)^2
\]


## Output files and result interpretation

When examples are run or the package is imported, several output files are generated in the `results/` directory.

## Monte Carlo ensembles versus branching pathway graphs

Both approaches are probabilistic and can use the same uncertainty and shock settings. The difference is the output representation:

- **Monte Carlo ensemble (spaghetti, probability bands, fan chart)**:
  - Many full trajectories \(z_{2025}, z_{2030}, \dots\) are run and summarized.
  - Best when time-series uncertainty (state probabilities, quantiles, expected value) is desired and when the state space is too large to map explicitly.
  - A distribution over outcomes is produced without explicitly constructing a scenario graph.

- **Branching pathway graph (scenario graph with edge weights)**:
  - A per-period graph is built where nodes are unique scenarios (typically attractors) and edges carry transition probabilities.
  - Transition probabilities are exact when enumerating and estimated when sampling.
  - Best when a readable set of distinct pathway archetypes, top-k most likely paths, and a compact scenario map for communication are desired.
  - In sampling mode, the result is an approximation of transition frequencies. With pruning (`top_paths`, `max_nodes_per_period`), rare branches are intentionally dropped for readability.

### Should outcomes match

- In principle, yes. If both methods represent the same stochastic model and enough samples are run, the branching-derived per-period summaries should converge to the Monte Carlo ensemble summaries.
- In practice, they can differ due to finite sampling noise, pruning and caps, and different sampling geometry. Full trajectories are sampled by Monte Carlo; local transition probabilities per node are estimated by branching and propagated forward.

### Monte Carlo run counts (testing and practice)

The number of Monte Carlo runs required depends on the method, the system size, and the intended use:

**Monte Carlo ensemble (full pathway simulation):**
- **Quicklook demos and testing:** \(M = 200\)–\(250\) runs can be acceptable if Monte Carlo error bars are reported. Approximate trends are provided and major pathways are identified.
- **Stable bands for reporting:** \(M \ge 2{,}000\) runs are preferred (and increased further for larger \(N\), more states, or many periods). Sampling noise in probability bands and quantile estimates is reduced, especially for rare events and tail probabilities.
- **Computational trade-off:** a complete trajectory across all periods is simulated by each run, so total cost scales linearly with \(M\) and the number of periods.

**Hybrid branching (transition sampling):**
- **Per-transition samples:** how many Monte Carlo draws are used to estimate transition probabilities from each parent node to its children is controlled by the `n_transition_samples` parameter. Default is 200; the example uses 120.
- **Total computational cost:** depends on the number of nodes per period and the number of periods. If a period has \(K\) nodes and each requires `n_transition_samples` draws, the cost for that transition layer is \(K \times\) `n_transition_samples`.
- **Testing vs production:** for quick testing, `n_transition_samples = 50`–\(120\) may suffice to identify major branches. For stable transition probability estimates (especially for rare but important transitions), 200–500 samples per transition are preferred.
- **Enumeration mode:** when the scenario space is small enough to enumerate (below `max_states_to_enumerate`), transition probabilities are exact and no sampling is needed.

**Node pruning (`max_nodes_per_period`):**
- **Purpose:** node explosion is limited by pruning low-probability scenarios at each period, keeping the branching graph readable and computationally manageable. Without pruning, the number of nodes can grow exponentially across periods.
- **How it works:** when the number of nodes in a period exceeds `max_nodes_per_period`, the top-\(K\) nodes ranked by incoming probability mass (sum of transition weights from all parent nodes) are kept by the builder. Transition probabilities are renormalized after pruning, and the graph remains connected (if a parent's outgoing edges are all pruned, it falls back to the most likely kept node).
- **Testing:** `max_nodes_per_period = 20`–\(40\) is set for quick exploration and visualization. Enough diversity is provided to see major pathway archetypes while keeping plots readable.
- **Production:** for comprehensive analysis, `max_nodes_per_period = 50`–\(100\) or `None` (no pruning) is considered. Rare but potentially important scenarios are preserved by higher values, at the cost of increased computation and visual complexity. The choice depends on whether completeness (capturing all significant pathways) or readability (focusing on high-probability paths) is prioritized.
- **Trade-off:** rare branches are intentionally dropped by pruning for readability, which can cause differences between branching-derived summaries and full Monte Carlo ensembles. If rare events need to be captured, either `max_nodes_per_period` is increased or Monte Carlo ensembles are used without explicit graph construction.

**Comparison:**
- Fewer total runs (200–2,000) are required by Monte Carlo ensembles but each run is a full trajectory. Best for estimating time-series marginals and overall distributional properties.
- More total samples (summed across all transitions) are required by hybrid branching but it can be more efficient when the branching factor is low or when enumeration is feasible. Best for explicit pathway structures and when distinct scenario archetypes need to be identified.
- Both methods benefit from more samples for stable estimates, but the computational geometry differs: Monte Carlo is trajectory-based; branching is node-based with local transition estimation.

### Example (branching pathway tree)

```python
import matplotlib.pyplot as plt

from cib import BranchingPathwayBuilder, DynamicVisualizer

builder = BranchingPathwayBuilder(
    base_matrix=matrix,
    periods=periods,
    initial=DATASET_B5_INITIAL_SCENARIO,
    cyclic_descriptors=dataset_b5_cyclic_descriptors(),
    threshold_rules=[dataset_b5_threshold_rule_fast_permitting()],
    max_states_to_enumerate=2000,
    n_transition_samples=120,
    max_nodes_per_period=40,
    base_seed=123,
    structural_sigma=0.15,
    judgment_sigma_scale_by_period=sigma_by_period,
    dynamic_tau=0.26,
    dynamic_rho=0.6,
    dynamic_innovation_dist="student_t",
    dynamic_innovation_df=5.0,
    dynamic_jump_prob=0.02,
    dynamic_jump_scale=0.70,
)

branching = builder.build(top_k=10)

plt.figure(figsize=(12, 4))
DynamicVisualizer.plot_pathway_tree(
    periods=branching.periods,
    scenarios_by_period=branching.scenarios_by_period,
    edges=branching.edges,
    top_paths=branching.top_paths,
    key_descriptors=["Policy_Stringency", "Permitting_Speed", "Electrification_Demand"],
    title="Branching pathway tree (top paths only)",
    min_edge_weight=0.03,
)
plt.tight_layout()
plt.show()
```

### Automatically generated files (on import)

- **`results/dataset_b5_cim.txt`**: Cross-impact matrix (CIM) in standard CIB text format.
  - All impact relationships between descriptors are contained.
  - Impact values with confidence codes (1–5) are shown for each relationship.
  - Format: Source[State] → Target[State] = Impact(Confidence).
  - Useful for understanding the complete impact structure and verifying workshop inputs.

- **`results/scenario_scoring_output.txt`**: Initial scenario diagnostics.
  - Consistency status (True/False).
  - Consistency margin (difference between the chosen state and the best alternative state).
  - Total impact score (sum of chosen-state scores).
  - Brink descriptors (descriptors near switching thresholds).
  - Impact balances for all descriptors that show scores for each state.
  - Useful for identifying unstable descriptors and diagnosing inconsistencies.

### Example output files (when running examples)

- **`results/example_dynamic_cib_notebook_plot_*.png`**: Visualizations that are generated from `examples/dynamic_cib.ipynb`.
  - Probability bands and numeric summaries for selected descriptors.
  - Branching pathway tree visualizations.
  - Scenario network plots, where enabled.

### Interpreting results

**CIM file (`dataset_b5_cim.txt`)**:
- Impact values range from -3 (strongly hindering) to +3 (strongly promoting).
- Confidence codes: 5 = very high (σ=0.2), 4 = high (σ=0.5), 3 = medium (σ=0.8), 2 = low (σ=1.2), 1 = very low (σ=1.5).
- Higher epistemic uncertainty in workshop judgments is indicated by lower confidence.

**Scenario scoring (`scenario_scoring_output.txt`)**:
- Consistency: True means all descriptors are in their optimal states given the scenario.
- Consistency margin: inconsistency is indicated by negative values; exact consistency is indicated by 0.
- Brink descriptors: descriptors where a different state could be flipped to by small changes.
- Impact balances: stronger support for that state is indicated by higher scores.

**Dynamic visualizations**:
- Probability bands: higher uncertainty about state outcomes is indicated by wider bands.
- Quantile bands: the 90% credible interval (5th to 95th percentile) of numeric outcomes is shown.
- Spaghetti plots: variability is shown by individual paths; stable pathways are indicated by clustering.
- Branching trees: more likely transitions are indicated by thicker edges; alternative futures are shown by multiple branches.

**Scenario network plots (final-period Monte Carlo summary)**:
- What nodes represent: each node is a distinct final-period scenario (a complete categorical state assignment across all descriptors) that is selected from the Monte Carlo ensemble.
- Node labels: `S11` is an index within the plotted subset. If a second line is shown (for example, `2`), it is the Monte Carlo count for that scenario.
- Node size: node size is proportional to scenario frequency when node weights are provided. This is a distribution visualization; there is no well-defined mean scenario for categorical state vectors.
- What edges represent: similarity between scenarios is represented by edges, not time evolution. With `edge_metric="hamming"`, scenarios are connected when they differ in a small number of descriptor-state choices, and edge weights reflect that distance.
- Why isolated nodes occur: a node can be isolated if no sufficiently similar neighbors exist within the plotted subset, or if connections are pruned by edge limits for readability.
